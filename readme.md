## ğŸš«ğŸ“§Spam Email Classification

A production-ready Spam Email Classification project with a modular codebase (ingestion â†’ preprocessing â†’ features â†’ training â†’ evaluation), Jupyter notebooks for EDA and clearance steps, logging & reports, and reproducible pipeline orchestration using DVC.

## ğŸ“ŒProject Summary

This repository implements a full ML workflow to detect spam emails.
It includes data ingestion, preprocessing, feature engineering, model training, evaluation, experiment tracking (via DVC), and generated logs/reports for audits and review.

.....................

Primary goals:
- Reproducible pipeline for spam detection
- Clear separation of steps (each stage is a separate file/module)
- Experiment tracking and remote storage using DVC
- Easy-to-run notebooks for EDA / clearance / demos

## ğŸ”‘Key Features

- Modular source code: ingestion â†’ preprocessing â†’ features â†’ training â†’ evaluation
- Jupyter notebooks for EDA and clearance checks
- Logging (logs/) and human-readable reports (reports/) produced automatically
- DVC pipeline (dvc.yaml) to reproduce entire workflow
- Model artifact storage (via DVC remote) and versioned experiments
- Automated tests (optional) to validate pipeline components

## ğŸ“‚Repo structure

Email-Spam-Classification/
â”‚-- src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ ingest.py            # Read external data sources / load raw data
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ preprocess.py        # Cleaning, text normalization, tokenization
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ build_features.py    # Vectorization (TF-IDF), embeddings,
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train.py             # Model training & save model (joblib/pickles)
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â””â”€â”€ evaluate.py          # Metrics, confusion matrix, ROC, PR curves
â”‚   
â”‚
â”‚-- notebooks/
â”‚   â””â”€â”€ 03_experiments.ipynb     # Experiment walkthroughs
â”‚
â”‚-- data/                        # (gitignored) raw and intermediate datasets
â”‚-- models/                      # (gitignored) saved model artifacts
â”‚-- reports/                     # (gitignored) generated reports, figures
â”‚-- logs/                        # (gitignored) run logs
â”‚-- dvc.yaml                     # DVC pipeline stages
â”‚-- params.yaml                  # Pipeline parameters (learning rate, etc.)
â”‚-- .gitignore
â”‚-- requirements.txt
â”‚-- README.md

## â–¶ï¸ How to run the pipeline (reproducible)

# reproduce all stages (ingest â†’ preprocess â†’ features â†’ train â†’ evaluate)
dvc repro
dvc dag
dvc repro train

## ğŸ§ªNotebooks & Clearance

- notebooks/03_experiments.ipynb â€” Quick experiments and visualization of metrics

Use notebooks for human review and to generate initial reports. Keep results reproducible by preferring the DVC pipeline for production runs.

## ğŸ“ŠLogging & Reports

- All runtime logs are written to logs/
- Evaluation outputs and charts saved to reports/ (both human-readable .md and artifact files)

## ğŸ” Experiments (DVC)

dvc exp run
dvc exp show
dvc exp apply <exp-id>
dvc exp remove <exp-id>

## ğŸ’»Tech Stack

Python (3.8+)
scikit-learn /
pandas, numpy, scikit-learn
DVC (pipeline & data versioning)
dvclive (optional, experiment logging)
joblib / cloud storage for artifacts

## ğŸ‘¨â€ğŸ’»Author

Shayan Ali

